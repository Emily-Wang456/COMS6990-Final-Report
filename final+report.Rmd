---
title: "Final Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, echo=FALSE}
library(prettydoc)
library(data.table)
library(plyr)
library(Hmisc)
library(DT)
#library(rworldmap)
```

## Introduction


```{r read_data, echo=FALSE}

dat <- fread(input = "~/Documents/GitHub/COMS6990-Final-Report/metadata/data.csv", verbose = FALSE)
region<-fread(input = "~/Documents/GitHub/COMS6990-Final-Report/metadata/Metadata_Country_API_SH.HIV.INCD.ZS_DS2_en_csv_v2.csv", verbose = FALSE)
category<- fread(input = "~/Documents/GitHub/COMS6990-Final-Report/metadata/Category.csv", verbose = FALSE)

datatable(dat[1:10,])

```

## Data cleaning

The main issue with the orignal data set is the structure and structural missing data. The columns of the orignal data are time series data and each row represents a specific indicator of a country. This structure is the transpose of the structure we usually use in R.So the first step of data cleaning is to adjust this dataset into a tidy dataset.

```{r data_melt}
##Remove the space in column name
old_name<-names(dat)[1:4]
new_name<-gsub(pattern = " ",replacement = ".",x=old_name)
setnames(x=dat,old = old_name,new = new_name)
##Stroe the indicator name and code into a new table and remove the indicator name from the original dataset.
Indicator<-dat[,3:4]
Indicator<-Indicator[,.(Indicator.Code=unique(Indicator.Code)),by=Indicator.Name]
sum(dat[,!is.na(V61)])
print("V61 is an emplty column")
dat[,`:=`(Indicator.Name=NULL,V61=NULL)]
##Reconstruct the data 
id.vars<-names(dat)[1:3]
measure.vars<-as.character(1960:2015)
mdat<-melt(data = dat,id.vars=1:3, measure.vars=measure.vars, variable.name = "year",variable.factor = FALSE)
mdat[, `:=`(value, mapvalues(x = value,from = "", to = NA))]
mdat[,`:=`(year=as.numeric(year),value=as.numeric(value))]
dcast_formula<-"Country.Code+Country.Name+year~Indicator.Code"
mdat<-dcast(mdat[],dcast_formula)
data.table(mdat[1:10, 1:5])

```

Since the original data set is a humongous dataset (348 columns in total), we want to pick up the variables that are only related to our analysis. To make futher analysis easier, we will classify each indicator and group the indicator that we are going to use in following analysis. To achieve this, first we manually picked 84
```{r subset}
##Subset the indicator we want and the data from 1990-2015
data.table(category[1:10, ])
sub_mdat<-mdat[year%in%1990:2015,.SD,.SDcols=c("Country.Code","Country.Name","year",unique(category$`Indicator Code`))]
##Use world bank Region Codelist to catefory data by region and subset only the region we want
region<-region[, 1:3]
sub_mdat<-merge(x=sub_mdat,y=region[,],by.y="Country Code",by.x="Country.Code",all.x=TRUE)
sub_region<-c("Latin America & Caribbean","South Asia","Sub-Saharan Africa","Middle East & North Africa")
sub_mdat<-sub_mdat[Region%in%sub_region,]
data.table(sub_mdat[1:10, c(1:5)])
```


```{r data_cleaning}
mean.missing <- function(x) {
return(mean(is.na(x)))
}
# calcualte the missing rate for each column (variable) by year
missing.rate <-sub_mdat[,lapply(.SD, mean.missing),by=year]

# evaluate the avarage missing rate for each column
average.missing.rate <- missing.rate[, lapply(.SD, FUN = mean)]

# find the columns that missing rate is less than 80%
# which(average.missing.rate < 0.8)

# the length of average missing rate less than 80%
cat("the number of variables that missing rate less than 80% is", length(which(average.missing.rate < 0.8)))
```
From code above, we narrow down 84 variables to 49. We'll do more investigation of these these 49 variable next week.
```{r data_merging}
# region<-as.data.table(countryRegions[,c("ISO3","REGION")])
# mdat<-merge(x=mdat,y=region,by.y="ISO3",by.x="Country.Code",all.x=TRUE)
```


